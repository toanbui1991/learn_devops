{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about running apachebeam template in dataflow**\n",
    "- dataflow is a serverless service to run data etl job. Therefore you do not need to set up server, we just need to send request with some configuration\n",
    "- reference link: https://github.com/GoogleCloudPlatform/python-docs-samples/tree/473749daea6b1f1d5a6a8826093a970f03ce0517/dataflow/run_template\n",
    "- content: discuss about how run apachebeam template in dataflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before you begin**\n",
    "- make sure we have:\n",
    "    - cloud storage bucket\n",
    "    - source and installed virtual environment wit installed google-api-python-client\n",
    "- there are multiple ways to communicate with google cloud services\n",
    "    - using cloud api (recommend ways)\n",
    "    - using python client package\n",
    "- reference for dataflow api (api is general documents for all languages:): https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.templates/launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about how to map between api document and python code**\n",
    "- end point: https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.templates/launch. dataflow.projects.templates.launch\n",
    "- python code: dataflow.prjects().templates().launch()\n",
    "- beside normal path parameter (required) and query parameter (optional), we have special parameter body which is request body for api request\n",
    "- on each end point documents we have request body format link and response body format link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package for google cloud client api: google-api-python-client\n",
    "#example of using google-api-python-client\n",
    "#end point: dataflow.projects.templates.launch.\n",
    "#end point reference: https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.templates/launch\n",
    "#python call: dataflow.projects().templates().launch()\n",
    "#it is good practice to read api end point document and request body, response body document\n",
    "#note: in this example, we already have temmplate\n",
    "from googleapiclient.discovery import build\n",
    "dataflow = build('dataflow', 'v1b3')\n",
    "request = dataflow.projects().templates().launch(\n",
    "    projectId=\"project\",\n",
    "    gcsPath=\"template\",\n",
    "    body={\n",
    "        'jobName': \"job\",\n",
    "        'parameters': {\"key_one\": \"value_one\", \"key_two\": \"value_two\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample code to prepare environment and code for this exercise:\n",
    "#for cloud storage related job we have gcloud storage vs gsutil cli. gsutils more detail for cloud storage task\n",
    "#- reference for gsutils: https://cloud.google.com/storage/docs/gsutil\n",
    "#- reference for gcloud cli: https://cloud.google.com/sdk/gcloud/reference\n",
    "#note about structure of google cloud product docs page: \n",
    "    #- each product docs page we have tabs like: overview, guides, references, samples, support, resources\n",
    "    # we care about reference (docs page), guides and samples\n",
    "#note about api reference:\n",
    "    #api document reference is not specific for any language. it is general interface for all language.\n",
    "    #google cloud api documents page is also organize as tabs: overview, reference (docs), guides, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code sample for run dataflow template\n",
    "#make cloud storage bucket with gsutils mb command\n",
    "!export BUCKET=your-gcs-bucket\n",
    "!gsutil mb gs://$BUCKET\n",
    "#clone code with git clone command\n",
    "!git clone https://github.com/GoogleCloudPlatform/python-docs-samples.git\n",
    "#change directory with cd command\n",
    "!cd python-docs-samples/dataflow/run_template\n",
    "#make and activate virtual environment, to isolate vironment (python version and package)\n",
    "!python3 -m venv venv\n",
    "!source venv/bin/activate\n",
    "#install requirement packages\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given that we have\n",
    "PROJECT=$(gcloud config get-value project) \\\n",
    "REGION=$(gcloud config get-value functions/region)\n",
    "\n",
    "# Deploy the Cloud Function. this will make cloud function running and the background and waiting for http request to trigger function\n",
    "!gcloud functions deploy run_template \\\n",
    "  --runtime python37 \\\n",
    "  --trigger-http \\\n",
    "  --region $REGION\n",
    "\n",
    "# Call the Cloud Function via an HTTP request. Every time we want to trigger function make a post request\n",
    "!curl -X POST \"https://$REGION-$PROJECT.cloudfunctions.net/run_template\" \\\n",
    "  -d project=$PROJECT \\\n",
    "  -d job=wordcount-$(date +'%Y%m%d-%H%M%S') \\\n",
    "  -d template=gs://dataflow-templates/latest/Word_Count \\\n",
    "  -d inputFile=gs://apache-beam-samples/shakespeare/kinglear.txt \\\n",
    "  -d output=gs://<your-gcs-bucket>/wordcount/outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataflow classic templates vs flex templates**\n",
    "- classic template: is apache beam pipeline as code\n",
    "- flex template: is apache beam pipeline but containerize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Type of api request**\n",
    "- GET: to get information\n",
    "- POST: to make request resource with information \n",
    "- PUT: to update resource with request body\n",
    "- DELETE: to delete resource resource"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "215640d84fea2d6a1578a868d021d57d26fe3fa314db54416f0ba6d81a3e2987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
