{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Google BigQuery I/O connector**\n",
    "- reference link: https://beam.apache.org/documentation/io/built-in/google-bigquery/\n",
    "- content: we will discuss about bigquery class and object in apache beam python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bigquery Basics**\n",
    "- Table names\n",
    "    - using a string: [project_id]:[dataset_id].[table_id]\n",
    "    - using a TableReference\n",
    "- Table rows\n",
    "    - BigQueryIO read and write transforms produce and consume data as a PCollection of dictionaries, where each element in the PCollection represents a single row in the table.\n",
    "    - a PCollection is a collection of each element is a dictionary. Each dictionary is a row in bigquery table\n",
    "- Schemas\n",
    "    - When writing to BigQuery, you must supply a table schema for the destination table that you want to write to\n",
    "- Data types\n",
    "    - reference link: https://beam.apache.org/documentation/io/built-in/google-bigquery/#data-types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create table schema**\n",
    "- using a TableSchema\n",
    "- using a string\n",
    "- referenc link: https://beam.apache.org/documentation/io/built-in/google-bigquery/#creating-a-table-schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import *\n",
    "import base64\n",
    "#create schema using talbe schema\n",
    "    #python present TableSchem object with dictionary\n",
    "table_schema = {\n",
    "    'fields': [{\n",
    "        'name': 'source', 'type': 'STRING', 'mode': 'NULLABLE'\n",
    "    }, {\n",
    "        'name': 'quote', 'type': 'STRING', 'mode': 'REQUIRED'\n",
    "    }]\n",
    "}\n",
    "#present table schem with string with format: “field1:type1,field2:type2,field3:type3” \n",
    "table_schema = 'source:STRING, quote:STRING'\n",
    "\n",
    "#bigquery data type and data presentation in bigquery\n",
    "bigquery_data = [{\n",
    "    'string': 'abc',\n",
    "    'bytes': base64.b64encode(b'\\xab\\xac'),\n",
    "    'integer': 5,\n",
    "    'float': 0.5,\n",
    "    'numeric': Decimal('5'),\n",
    "    'boolean': True,\n",
    "    'timestamp': '2018-12-31 12:44:31.744957 UTC',\n",
    "    'date': '2018-12-31',\n",
    "    'time': '12:44:31',\n",
    "    'datetime': '2018-12-31T12:44:31',\n",
    "    'geography': 'POINT(30 10)'\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read from BigQuery**\n",
    "- read from a table\n",
    "- read from a query\n",
    "- using storage read api. Python sdk still not supporting it\n",
    "- reference link: https://beam.apache.org/documentation/io/built-in/google-bigquery/#reading-from-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of read data from bigquery with a query\n",
    "import apache_beam as beam\n",
    "max_temperatures = (\n",
    "    pipeline\n",
    "    | 'QueryTableStdSQL' >> beam.io.ReadFromBigQuery(\n",
    "        query='SELECT max_temperature FROM '\\\n",
    "              '`clouddataflow-readonly.samples.weather_stations`',\n",
    "        use_standard_sql=True)\n",
    "    # Each row is a dictionary where the keys are the BigQuery columns\n",
    "    | beam.Map(lambda elem: elem['max_temperature']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing to Bigquery**\n",
    "When you apply a write transform, you must provide the following information for the destination table(s):\n",
    "\n",
    "- The table name.\n",
    "- The destination table’s create disposition. The create disposition specifies whether the destination table must exist or can be created by the write operation.\n",
    "- The destination table’s write disposition. The write disposition specifies whether the data you write will replace an existing table, append rows to an existing table, or write only to an empty table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create disposition**\n",
    "- decide whether or not to create table when writing transform\n",
    "- BigQueryDisposition.CREATE_IF_NEEDED: create table when table is not exist\n",
    "- BigQueryDisposition.CREATE_NEVER: never create table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write disposition**\n",
    "- attribute to control how to write to an existing table\n",
    "- BigQueryDisposition.WRITE_EMPTY\n",
    "- BigQueryDisposition.WRITE_TRUNCATE\n",
    "- BigQueryDisposition.WRITE_APPEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of writing data to a table\n",
    "    #1 specify table\n",
    "    #2 specify schem\n",
    "    #3 specify create_disposition and write_disposition\n",
    "quotes = pipeline | beam.Create([\n",
    "    {\n",
    "        'source': 'Mahatma Gandhi', 'quote': 'My life is my message.'\n",
    "    },\n",
    "    {\n",
    "        'source': 'Yoda', 'quote': \"Do, or do not. There is no 'try'.\"\n",
    "    },\n",
    "])\n",
    "quotes | beam.io.WriteToBigQuery(\n",
    "    table_spec,\n",
    "    schema=table_schema,\n",
    "    write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
    "    create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: Using dynamic destinations\n",
    "fictional_characters_view = beam.pvalue.AsDict(\n",
    "    pipeline | 'CreateCharacters' >> beam.Create([('Yoda', True),\n",
    "                                                  ('Obi Wan Kenobi', True)]))\n",
    "\n",
    "def table_fn(element, fictional_characters):\n",
    "  if element in fictional_characters:\n",
    "    return 'my_dataset.fictional_quotes'\n",
    "  else:\n",
    "    return 'my_dataset.real_quotes'\n",
    "\n",
    "quotes | 'WriteWithDynamicDestination' >> beam.io.WriteToBigQuery(\n",
    "    table_fn,\n",
    "    schema=table_schema,\n",
    "    table_side_inputs=(fictional_characters_view, ),\n",
    "    write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
    "    create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of specify partitioni when writing table\n",
    "quotes | 'WriteWithTimePartitioning' >> beam.io.WriteToBigQuery(\n",
    "    table_spec,\n",
    "    schema=table_schema,\n",
    "    write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
    "    create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "    additional_bq_parameters={'timePartitioning': {\n",
    "        'type': 'HOUR'\n",
    "    }})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the insertion method**\n",
    "- there are two insert method:\n",
    "    - FILE_LOADS\n",
    "    - STREAMING_INSERTS\n",
    "- note with file loads method: with files load method we have to specif temp bucket (data is stored in temp bucket before write to bigquery table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of specify insert method: \n",
    "WriteToBigQuery(method='FILE_LOADS')\n",
    "WriteToBigQuery(method='STREAMING_INSERTS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "215640d84fea2d6a1578a868d021d57d26fe3fa314db54416f0ba6d81a3e2987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
